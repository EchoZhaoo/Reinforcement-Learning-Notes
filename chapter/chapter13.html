
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Chapter 13: Policy Gradient Methods · Reinforcement Learning: An Introduction(2nd)</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-anchors/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    
    <link rel="prev" href="chapter12.html" />
    

    <style>
    @media only screen and (max-width: 640px) {
        .book-header .hidden-mobile {
            display: none;
        }
    }
    </style>
    <script>
        window["gitbook-plugin-github-buttons"] = {"repo":"laddie132/Reinforcement-Learning-Notes","types":["star","watch","fork"],"size":"small"};
    </script>

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    README
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    Part I
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" >
            
                <span>
            
                    
                    Chapter 1: Introduction
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="chapter2.html">
            
                <a href="chapter2.html">
            
                    
                    Chapter 2: Multi-armed Bandits
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="chapter3.html">
            
                <a href="chapter3.html">
            
                    
                    Chapter 3: Finite Markov Decision Processes
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.4" data-path="chapter4.html">
            
                <a href="chapter4.html">
            
                    
                    Chapter 4: Dynamic Programming
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.5" data-path="chapter5.html">
            
                <a href="chapter5.html">
            
                    
                    Chapter 5: Monte Carlo Methods
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.6" data-path="chapter6.html">
            
                <a href="chapter6.html">
            
                    
                    Chapter 6: Temporal-Diﬀerence Learning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.7" data-path="chapter7.html">
            
                <a href="chapter7.html">
            
                    
                    Chapter 7: n-step Bootstrapping
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.8" data-path="chapter8.html">
            
                <a href="chapter8.html">
            
                    
                    Chapter 8: Planning and Learning with Tabular Methods
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    Part II
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="chapter9.html">
            
                <a href="chapter9.html">
            
                    
                    Chapter 9: On-policy Prediction with Approximation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="chapter10.html">
            
                <a href="chapter10.html">
            
                    
                    Chapter 10: On-policy Control with Approximation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" >
            
                <span>
            
                    
                    Chapter 11: Oﬀ-policy Methods with Approximation
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="chapter12.html">
            
                <a href="chapter12.html">
            
                    
                    Chapter 12: Eligibility Traces
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.5" data-path="chapter13.html">
            
                <a href="chapter13.html">
            
                    
                    Chapter 13: Policy Gradient Methods
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    Part III
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="chapter14.html">
            
                <a href="chapter14.html">
            
                    
                    Chapter 14: Psychology
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="chapter15.html">
            
                <a href="chapter15.html">
            
                    
                    Chapter 15: Neuroscience
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" >
            
                <span>
            
                    
                    Chapter 16: Applications and Case Studies
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >Chapter 13: Policy Gradient Methods</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="chapter-13-policy-gradient-methods"><a name="chapter-13-policy-gradient-methods" class="plugin-anchor" href="#chapter-13-policy-gradient-methods"><i class="fa fa-link" aria-hidden="true"></i></a>Chapter 13 Policy Gradient Methods</h1>
<p>&#x4E4B;&#x524D;&#x6240;&#x5B66;&#x5230;&#x7684;&#x90FD;&#x662F;&#x57FA;&#x4E8E;&#x52A8;&#x4F5C;&#x503C;&#x51FD;&#x6570;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x8FD9;&#x4E00;&#x7AE0;&#x5219;&#x662F;&#x53C2;&#x6570;&#x5316;&#x7B56;&#x7565;&#x7684;&#x65B9;&#x6CD5;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x5B9A;&#x4E49;&#x7B56;&#x7565;&#x4E3A;&#x5982;&#x4E0B;&#x6570;&#x5B66;&#x5F0F;&#xFF1A;
<script type="math/tex; mode=display">
\pi ( a | s , \theta ) = \operatorname { Pr } \left\{ A _ { t } = a | S _ { t } = s , \theta _ { t } = \theta \right\}
</script>
&#x5E76;&#x4E14;&#x4F7F;&#x7528;$J ( \theta )$&#x8861;&#x91CF;&#x6A21;&#x578B;&#x7684;&#x597D;&#x574F;&#xFF0C;&#x4F7F;&#x7528;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x66F4;&#x65B0;&#x6743;&#x91CD;&#x5982;&#x4E0B;&#xFF1A;
<script type="math/tex; mode=display">
\boldsymbol { \theta } _ { t + 1 } = \boldsymbol { \theta } _ { t } + \alpha \overline { \nabla J \left( \boldsymbol { \theta } _ { t } \right) }
</script>
&#x51E1;&#x662F;&#x9075;&#x5FAA;&#x8FD9;&#x79CD;&#x6A21;&#x5F0F;&#x7684;&#x65B9;&#x6CD5;&#x90FD;&#x79F0;&#x4F5C;&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x5176;&#x4E2D;&#xFF0C;&#x540C;&#x65F6;&#x5B66;&#x4E60;&#x503C;&#x51FD;&#x6570;&#x7684;&#x65B9;&#x6CD5;&#x79F0;&#x4F5C;actor-critic&#x3002;</p>
<h2 id="131-policy-approximation-and-its-advantages"><a name="131-policy-approximation-and-its-advantages" class="plugin-anchor" href="#131-policy-approximation-and-its-advantages"><i class="fa fa-link" aria-hidden="true"></i></a>13.1 Policy Approximation and its Advantages</h2>
<p>&#x9996;&#x5148;&#x662F;&#x79BB;&#x6563;&#x52A8;&#x4F5C;&#x7A7A;&#x95F4;&#x7684;&#x65B9;&#x6CD5;&#x3002;&#x901A;&#x5E38;&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x6BCF;&#x4E2A;&#x72B6;&#x6001;-&#x52A8;&#x4F5C;&#x5BF9;&#x7684;&#x6570;&#x5B57;&#x5316;&#x504F;&#x597D;&#x7A0B;&#x5EA6;$h ( s , a , \theta ) \in \mathbb { R }$&#xFF0C;&#x76F4;&#x63A5;&#x9009;&#x62E9;&#x6700;&#x5927;&#x503C;&#x5BF9;&#x5E94;&#x52A8;&#x4F5C;&#x5373;&#x53EF;&#x3002;&#x5982;&#x679C;&#x4F7F;&#x7528;softmax&#x5904;&#x7406;&#xFF0C;&#x5219;&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x5B8C;&#x6574;&#x7684;&#x6982;&#x7387;&#x5206;&#x5E03;&#xFF0C;&#x5982;&#x4E0B;&#xFF1A;
<script type="math/tex; mode=display">
\pi ( a | s , \boldsymbol { \theta } ) \doteq \frac { e ^ { h ( s , a , \boldsymbol { \theta } ) } } { \sum _ { b } e ^ { h ( s , b , \boldsymbol { \theta } ) } }
</script>
&#x4E0A;&#x8FF0;&#x8FD9;&#x79CD;&#x5F62;&#x5F0F;&#x7684;&#x53C2;&#x6570;&#x5316;&#x7B56;&#x7565;&#x79F0;&#x4F5C;softmax in action preferences&#xFF0C;&#x5176;&#x4E2D;&#x7684;h&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x91C7;&#x7528;&#x4EFB;&#x610F;&#x7684;&#x62DF;&#x5408;&#x65B9;&#x6CD5;&#xFF0C;&#x5982;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#x7B49;&#x7B49;&#x3002;</p>
<p>&#x76F8;&#x8F83;&#x4E8E;&#x52A8;&#x4F5C;&#x503C;&#x51FD;&#x6570;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x53C2;&#x6570;&#x5316;&#x7B56;&#x7565;&#x6709;&#x4EE5;&#x4E0B;&#x4F18;&#x70B9;&#xFF1A;</p>
<ol>
<li>&#x6700;&#x7EC8;&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x4E00;&#x4E2A;&#x786E;&#x5B9A;&#x7684;&#x7B56;&#x7565;&#xFF0C;&#x800C;$\epsilon-greedy$&#x6709;&#x4E00;&#x5B9A;&#x6982;&#x7387;&#x968F;&#x673A;&#x9009;&#x62E9;&#x52A8;&#x4F5C;&#x3002;</li>
<li>&#x5141;&#x8BB8;&#x4EE5;&#x4EFB;&#x610F;&#x6982;&#x7387;&#x9009;&#x62E9;&#x67D0;&#x4E2A;&#x52A8;&#x4F5C;&#x3002;</li>
<li>&#x7B56;&#x7565;&#x51FD;&#x6570;&#x53EF;&#x80FD;&#x66F4;&#x52A0;&#x76F4;&#x63A5;&#xFF0C;&#x5E76;&#x4E14;&#x62DF;&#x5408;&#x66F4;&#x52A0;&#x7B80;&#x5355;&#x3002;</li>
<li>&#x4FBF;&#x4E8E;&#x6DFB;&#x52A0;&#x5148;&#x9A8C;&#x77E5;&#x8BC6;&#x3002;</li>
</ol>
<h2 id="132-the-policy-gradient-theorem"><a name="132-the-policy-gradient-theorem" class="plugin-anchor" href="#132-the-policy-gradient-theorem"><i class="fa fa-link" aria-hidden="true"></i></a>13.2 The Policy Gradient Theorem</h2>
<p>&#x9664;&#x4E86;&#x4E0A;&#x8282;&#x4E2D;&#x4F18;&#x70B9;&#x4E4B;&#x5916;&#xFF0C;&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x7684;&#x65B9;&#x6CD5;&#x4F7F;&#x5F97;&#x52A8;&#x4F5C;&#x6982;&#x7387;&#x53EF;&#x4EE5;&#x5E73;&#x6ED1;&#x53D8;&#x5316;&#xFF0C;&#x800C;&#x4E0D;&#x662F;&#x50CF;$\epsilon-greedy$&#x4E2D;&#x52A8;&#x4F5C;&#x53EF;&#x80FD;&#x53D1;&#x751F;&#x7A81;&#x53D8;&#x3002;&#x6B63;&#x662F;&#x7531;&#x4E8E;&#x4F9D;&#x8D56;&#x4E8E;&#x7B56;&#x7565;&#x8FDE;&#x7EED;&#x6027;&#xFF0C;&#x4F7F;&#x5F97;&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x7684;&#x65B9;&#x6CD5;&#x903C;&#x8FD1;&#x68AF;&#x5EA6;&#x4E0A;&#x5347;&#x8FC7;&#x7A0B;&#x3002;</p>
<p>&#x9488;&#x5BF9;&#x7247;&#x6BB5;&#x5F0F;&#x4EFB;&#x52A1;&#x800C;&#x8A00;&#xFF0C;&#x5B9A;&#x4E49;&#x8BC4;&#x4EF7;&#x6307;&#x6807;&#x4E3A;&#x8D77;&#x59CB;&#x72B6;&#x6001;&#x7684;&#x503C;&#x51FD;&#x6570;&#xFF0C;&#x5982;&#x4E0B;&#xFF1A;
<script type="math/tex; mode=display">
J ( \boldsymbol { \theta } ) \doteq v _ { \pi _ { \boldsymbol { \theta } } } \left( s _ { 0 } \right)
</script>
&#x4EE5;&#x4E0A;&#x6307;&#x6807;&#x4F9D;&#x8D56;&#x4E8E;&#x72B6;&#x6001;&#x5206;&#x5E03;&#xFF0C;&#x8BA1;&#x7B97;&#x5BF9;&#x4E8E;&#x7B56;&#x7565;&#x53C2;&#x6570;&#x7684;&#x68AF;&#x5EA6;&#x503C;&#x8F83;&#x4E3A;&#x56F0;&#x96BE;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x6709;&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x5B9A;&#x7406;&#x5982;&#x4E0B;&#xFF0C;&#x4E0D;&#x6D89;&#x53CA;&#x72B6;&#x6001;&#x5206;&#x5E03;&#xFF1A;
<script type="math/tex; mode=display">
\nabla J ( \theta ) \propto \sum _ { s } \mu ( s ) \sum _ { a } q _ { \pi } ( s , a ) \nabla \pi ( a | s , \theta )
</script>
&#x5728;&#x7247;&#x6BB5;&#x5F0F;&#x4EFB;&#x52A1;&#x4E2D;&#xFF0C;&#x6BD4;&#x4F8B;&#x503C;&#x53D6;&#x7247;&#x6BB5;&#x7684;&#x5E73;&#x5747;&#x957F;&#x5EA6;&#xFF1B;&#x5BF9;&#x4E8E;&#x8FDE;&#x7EED;&#x5F0F;&#x4EFB;&#x52A1;&#xFF0C;&#x5219;&#x53D6;1&#x3002;</p>
<h2 id="133-reinforce-monte-carlo-policy-gradient"><a name="133-reinforce-monte-carlo-policy-gradient" class="plugin-anchor" href="#133-reinforce-monte-carlo-policy-gradient"><i class="fa fa-link" aria-hidden="true"></i></a>13.3 REINFORCE: Monte Carlo Policy Gradient</h2>
<p>&#x4E0A;&#x4E00;&#x8282;&#x4E2D;&#x7684;&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x5B9A;&#x7406;&#x53EF;&#x4EE5;&#x6539;&#x5199;&#x4E3A;&#x671F;&#x671B;&#x5F62;&#x5F0F;&#xFF0C;&#x5982;&#x4E0B;&#xFF1A;
<script type="math/tex; mode=display">
\left.\begin{aligned} \nabla J ( \boldsymbol { \theta } ) & \propto \sum _ { s } \mu ( s ) \sum _ { a } q _ { \pi } ( s , a ) \nabla \pi ( a | s , \boldsymbol { \theta } ) \\ & = \mathbb { E } _ { \pi } \left[ \sum _ { a } q _ { \pi } \left( S _ { t } , a \right) \nabla \pi ( a | S _ { t } , \boldsymbol { \theta } ) \right]  \\
&= \mathbb { E } _ { \pi } \left[ q _ { \pi } \left( S _ { t } , A _ { t } \right) \frac { \nabla \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } \right) } { \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } \right) } \right]\\
& = \mathbb { E } _ { \pi } \left[ G _ { t } \frac { \nabla \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } \right) } { \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } \right) } \right]
\end{aligned} \right.
</script>
&#x5176;&#x4E2D;&#xFF0C;Gt&#x5373;&#x4E3A;&#x8FD4;&#x56DE;&#x503C;&#xFF0C;&#x5219;&#x6743;&#x91CD;&#x66F4;&#x65B0;&#x516C;&#x5F0F;&#x5982;&#x4E0B;&#xFF1A;
<script type="math/tex; mode=display">
\boldsymbol { \theta } _ { t + 1 } \doteq \boldsymbol { \theta } _ { t } + \alpha G _ { t } \frac { \nabla \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) } { \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) }
</script>
&#x8FD9;&#x4E2A;&#x7B97;&#x6CD5;&#x4E5F;&#x79F0;&#x4F5C;REINFORCE&#x7B97;&#x6CD5;&#xFF0C;&#x56E0;&#x4E3A;&#x4F7F;&#x7528;&#x4E86;&#x67D0;&#x4E2A;&#x65F6;&#x523B;&#x7684;&#x5B8C;&#x6574;&#x8FD4;&#x56DE;&#x503C;&#xFF0C;&#x56E0;&#x6B64;REINFORCE&#x4E5F;&#x662F;&#x4E00;&#x79CD;MC&#x7B97;&#x6CD5;&#xFF0C;&#x53EA;&#x5B9A;&#x4E49;&#x5728;&#x7247;&#x6BB5;&#x5F0F;&#x4EFB;&#x52A1;&#x4E2D;&#x3002;</p>
<p><img src="../img/13-3-1.png" alt="img"></p>
<p>&#x4E0A;&#x56FE;&#x4E2D;&#x7ED9;&#x51FA;&#x7684;&#x7B97;&#x6CD5;&#x66FF;&#x6362;&#x4E3A;&#x5BF9;&#x6570;&#x5BFC;&#x6570;&#xFF0C;&#x5E76;&#x4E14;&#x5F15;&#x5165;&#x4E86;&#x6298;&#x6263;&#x60C5;&#x51B5;&#x3002;</p>
<p>&#x8FD9;&#x79CD;REINFORCE&#x7B97;&#x6CD5;&#x5177;&#x6709;&#x9AD8;&#x65B9;&#x5DEE;&#x7684;&#x7279;&#x70B9;&#xFF0C;&#x5B66;&#x4E60;&#x8FC7;&#x7A0B;&#x8F83;&#x6162;&#x3002;</p>
<h2 id="134-reinforce-with-baseline"><a name="134-reinforce-with-baseline" class="plugin-anchor" href="#134-reinforce-with-baseline"><i class="fa fa-link" aria-hidden="true"></i></a>13.4 REINFORCE with Baseline</h2>
<p>&#x4E0A;&#x4E00;&#x8282;&#x4E2D;&#x7684;&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x5B9A;&#x7406;&#x53EF;&#x4EE5;&#x6269;&#x5C55;&#x5230;baseline&#x7684;&#x60C5;&#x51B5;&#xFF0C;&#x5982;&#x4E0B;&#xFF1A;
<script type="math/tex; mode=display">
\nabla J ( \theta ) \propto \sum _ { s } \mu ( s ) \sum _ { a } \left( q _ { \pi } ( s , a ) - b ( s ) \right) \nabla \pi ( a | s , \theta )
</script>
&#x53EA;&#x8981;&#x6EE1;&#x8DB3;baseline&#x51FD;&#x6570;&#x4E0E;&#x52A8;&#x4F5C;a&#x65E0;&#x5173;&#x5373;&#x53EF;&#xFF0C;&#x5219;&#x6743;&#x91CD;&#x8DDF;&#x65B0;&#x5982;&#x4E0B;&#xFF1A;
<script type="math/tex; mode=display">
\boldsymbol { \theta } _ { t + 1 } \doteq \boldsymbol { \theta } _ { t } + \alpha \left( G _ { t } - b \left( S _ { t } \right) \right) \frac { \nabla \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) } { \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) }
</script>
&#x5E26;baseline&#x7684;REINFORCE&#x7B97;&#x6CD5;&#xFF0C;&#x4F7F;&#x5F97;&#x66F4;&#x65B0;&#x7684;&#x671F;&#x671B;&#x503C;&#x4E0D;&#x53D8;&#xFF0C;&#x4F46;&#x65B9;&#x5DEE;&#x5927;&#x5927;&#x964D;&#x4F4E;&#x3002;&#x4E00;&#x79CD;&#x5E38;&#x89C1;&#x7684;baseline&#x9009;&#x62E9;&#x65B9;&#x5F0F;&#x662F;&#x52A8;&#x4F5C;&#x503C;&#x51FD;&#x6570;&#xFF0C;&#x56E0;&#x6B64;&#x53EA;&#x9700;&#x8981;&#x540C;&#x65F6;&#x5B66;&#x4E60;&#x52A8;&#x4F5C;&#x503C;&#x51FD;&#x6570;&#x7F51;&#x7EDC;&#x7684;&#x53C2;&#x6570;&#x5373;&#x53EF;&#x3002;</p>
<p><img src="../img/13-4-1.png" alt="img"></p>
<p>&#x8BE5;&#x7B97;&#x6CD5;&#x6709;&#x4E24;&#x4E2A;&#x6B65;&#x957F;&#xFF0C;&#x9700;&#x8981;&#x624B;&#x52A8;&#x8BBE;&#x7F6E;&#x5982;&#x4F55;&#x8C03;&#x6574;&#x3002;</p>
<h2 id="135-actor&#x2013;critic-methods"><a name="135-actor&#x2013;critic-methods" class="plugin-anchor" href="#135-actor&#x2013;critic-methods"><i class="fa fa-link" aria-hidden="true"></i></a>13.5 Actor&#x2013;Critic Methods</h2>
<p>&#x5C3D;&#x7BA1;&#x5E26;baseline&#x7684;REINFORCE&#x7B97;&#x6CD5;&#x540C;&#x65F6;&#x5B66;&#x4E60;&#x52A8;&#x4F5C;&#x503C;&#x51FD;&#x6570;&#x548C;&#x7B56;&#x7565;&#xFF0C;&#x4F46;&#x4ECD;&#x4E0D;&#x662F;actor-critic&#x7B97;&#x6CD5;&#xFF0C;&#x56E0;&#x4E3A;&#x6CA1;&#x6709;&#x4F7F;&#x7528;&#x81EA;&#x5F15;&#x5BFC;&#x673A;&#x5236;&#x3002;&#x901A;&#x8FC7;&#x81EA;&#x5F15;&#x5BFC;&#x548C;&#x4F9D;&#x8D56;&#x72B6;&#x6001;&#x8868;&#x793A;&#x6240;&#x5F15;&#x5165;&#x7684;&#x504F;&#x5DEE;&#x901A;&#x5E38;&#x662F;&#x6709;&#x76CA;&#x7684;&#xFF0C;&#x56E0;&#x4E3A;&#x8FD9;&#x53EF;&#x4EE5;&#x964D;&#x4F4E;&#x65B9;&#x5DEE;&#xFF0C;&#x5E76;&#x4E14;&#x52A0;&#x901F;&#x5B66;&#x4E60;&#x3002;&#x800C;&#x5E26;baseline&#x7684;REINFORCE&#x662F;&#x65E0;&#x504F;&#x7684;&#x3002;</p>
<p>one-step actor-critic&#x5C06;&#x8FD4;&#x56DE;&#x503C;&#x66FF;&#x6362;&#x4E3A;one-step return&#x5373;&#x53EF;&#xFF0C;&#x5982;&#x4E0B;&#xFF1A;
<script type="math/tex; mode=display">
\left.\begin{aligned} \boldsymbol { \theta } _ { t + 1 } &\doteq \boldsymbol { \theta } _ { t } + \alpha \left( G _ { t : t + 1 } - \hat { v } \left( S _ { t } , \mathbf { w } \right) \right)  \frac { \nabla \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) } { \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) } \\ & = \boldsymbol { \theta } _ { t } + \alpha \left( R _ { t + 1 } + \gamma \hat { v } \left( S _ { t + 1 } , \mathbf { w } \right) - \hat { v } \left( S _ { t } , \mathbf { w } \right) \right) \frac { \nabla \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) } { \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) } \\ & = \boldsymbol { \theta } _ { t } + \alpha \delta _ { t } \frac { \nabla \pi \left( A _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) } { \pi \left( S _ { t } | S _ { t } , \boldsymbol { \theta } _ { t } \right) } \end{aligned} \right.
</script>
&#x72B6;&#x6001;&#x503C;&#x51FD;&#x6570;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;semi-gradient TD(0)&#x7684;&#x65B9;&#x6CD5;&#x8FDB;&#x884C;&#x5B66;&#x4E60;&#x3002;</p>
<p><img src="../img/13-5-2.png" alt="img"></p>
<p>&#x4E0A;&#x8FF0;&#x662F;&#x4E00;&#x79CD;&#x524D;&#x5411;&#x7B97;&#x6CD5;&#xFF0C;&#x800C;&#x540E;&#x5411;&#x7684;$\lambda$-return&#x7B97;&#x6CD5;&#x4E5F;&#x5341;&#x5206;&#x5E38;&#x7528;&#xFF0C;&#x5B8C;&#x6574;&#x7684;&#x4F2A;&#x4EE3;&#x7801;&#x5982;&#x4E0B;&#xFF1A;</p>
<p><img src="../img/13-5-1.png" alt="img"></p>
<h2 id="136-policy-gradient-for-continuing-problems"><a name="136-policy-gradient-for-continuing-problems" class="plugin-anchor" href="#136-policy-gradient-for-continuing-problems"><i class="fa fa-link" aria-hidden="true"></i></a>13.6 Policy Gradient for Continuing Problems</h2>
<p>&#x5BF9;&#x4E8E;&#x8FDE;&#x7EED;&#x5F0F;&#x4EFB;&#x52A1;&#xFF0C;&#x5B9A;&#x4E49;&#x8BC4;&#x4EF7;&#x6307;&#x6807;&#x4E3A;&#x6BCF;&#x4E2A;&#x65F6;&#x523B;&#x5956;&#x52B1;&#x7684;&#x5747;&#x503C;&#xFF0C;&#x5982;&#x4E0B;&#xFF1A;
<script type="math/tex; mode=display">
\left.\begin{aligned} J ( \boldsymbol { \theta } ) \doteq r ( \pi ) & \doteq \lim _ { h \rightarrow \infty } \frac { 1 } { h } \sum _ { t = 1 } ^ { h } \mathbb { E } \left[ R _ { t } | A _ { 0 : t - 1 } \sim \pi \right] \\ & = \lim _ { t \rightarrow \infty } \mathbb { E } \left[ R _ { t } | A _ { 0 : t - 1 } \sim \pi \right] \\ & = \sum _ { s } \mu ( s ) \sum _ { a } \pi ( a | s ) \sum _ { s ^ { \prime } , r } p \left( s ^ { \prime } , r | s , a \right) r \end{aligned} \right.
</script>
&#x53E6;&#x5916;&#xFF0C;&#x5B9A;&#x4E49;&#x7684;&#x503C;&#x51FD;&#x6570;&#x4E5F;&#x90FD;&#x662F;&#x5DEE;&#x503C;&#x503C;&#x51FD;&#x6570;&#x3002;</p>
<p><img src="../img/13-6-1.png" alt="img"></p>
<h2 id="137-policy-parameterization-for-continuous-actions"><a name="137-policy-parameterization-for-continuous-actions" class="plugin-anchor" href="#137-policy-parameterization-for-continuous-actions"><i class="fa fa-link" aria-hidden="true"></i></a>13.7 Policy Parameterization for Continuous Actions</h2>
<p>&#x4E4B;&#x524D;&#x6240;&#x8BA8;&#x8BBA;&#x7684;&#x90FD;&#x662F;&#x79BB;&#x6563;&#x52A8;&#x4F5C;&#x7A7A;&#x95F4;&#xFF0C;&#x5BF9;&#x4E8E;&#x8FDE;&#x7EED;&#x52A8;&#x4F5C;&#x7A7A;&#x95F4;&#xFF0C;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x4E00;&#x4E2A;&#x6982;&#x7387;&#x5206;&#x5E03;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x7B56;&#x7565;&#x53EF;&#x4EE5;&#x5B9A;&#x4E49;&#x4E3A;&#x5B9E;&#x6570;&#x52A8;&#x4F5C;&#xFF0C;&#x800C;&#x52A8;&#x4F5C;&#x9009;&#x62E9;&#x7684;&#x6982;&#x7387;&#x5BF9;&#x5E94;&#x4E3A;&#x9AD8;&#x65AF;&#x6982;&#x7387;&#x5BC6;&#x5EA6;&#x51FD;&#x6570;&#x4E0A;&#x7684;&#x503C;&#xFF0C;&#x9700;&#x8981;&#x5B66;&#x4E60;&#x7684;&#x5219;&#x662F;&#x9AD8;&#x65AF;&#x51FD;&#x6570;&#x7684;&#x5747;&#x503C;&#x548C;&#x65B9;&#x5DEE;&#x3002;</p>
<h2 id="138-summary"><a name="138-summary" class="plugin-anchor" href="#138-summary"><i class="fa fa-link" aria-hidden="true"></i></a>13.8 Summary</h2>
<p>&#x8FD9;&#x4E00;&#x7AE0;&#x4E3B;&#x8981;&#x4ECB;&#x7ECD;&#x76F4;&#x63A5;&#x5B66;&#x4E60;&#x53C2;&#x6570;&#x5316;&#x7B56;&#x7565;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x5373;&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x7684;&#x65B9;&#x6CD5;&#x3002;</p>
<p>&#x6838;&#x5FC3;&#x539F;&#x7406;&#x662F;&#x7B56;&#x7565;&#x68AF;&#x5EA6;&#x5B9A;&#x7406;&#x3002;&#x7B97;&#x6CD5;&#x5305;&#x62EC;REINFORCE&#x3001;&#x5E26;baseline&#x7684;REINFORCE&#x548C;actor-critic&#x7B49;&#x3002;</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="chapter12.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page: Chapter 12: Eligibility Traces">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Chapter 13: Policy Gradient Methods","level":"1.3.5","depth":2,"next":{"title":"Part III","level":"1.4","depth":1,"ref":"","articles":[{"title":"Chapter 14: Psychology","level":"1.4.1","depth":2,"path":"chapter/chapter14.md","ref":"chapter/chapter14.md","articles":[]},{"title":"Chapter 15: Neuroscience","level":"1.4.2","depth":2,"path":"chapter/chapter15.md","ref":"chapter/chapter15.md","articles":[]},{"title":"Chapter 16: Applications and Case Studies","level":"1.4.3","depth":2,"ref":"","articles":[]}]},"previous":{"title":"Chapter 12: Eligibility Traces","level":"1.3.4","depth":2,"path":"chapter/chapter12.md","ref":"chapter/chapter12.md","articles":[]},"dir":"ltr"},"config":{"plugins":["anchors","back-to-top-button","github","github-buttons","mathjax","livereload"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"github":{"url":"https://github.com/laddie132"},"livereload":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"back-to-top-button":{},"github-buttons":{"repo":"laddie132/Reinforcement-Learning-Notes","types":["star","watch","fork"],"size":"small"},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false},"anchors":{}},"theme":"default","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"Reinforcement Learning: An Introduction(2nd)","language":"zh-hans","gitbook":"*"},"file":{"path":"chapter/chapter13.md","mtime":"2018-09-19T06:33:13.000Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2019-04-10T10:13:19.489Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-github-buttons/plugin.js"></script>
        
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

